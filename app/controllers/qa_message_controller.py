from app.models.chat_model import ChatHistory
from app.schemas.responses import MessageRequest, MessageResponse, ChatHistoryResponse
from app.controllers.llm_service import generate_response, process_stream
from app.utils.reflection import Reflection
from app.config import REFLECTION
from app.prompt.tutor_prompt import AITutorPrompt
from typing import Dict, List, Any

class ChatSessionManager:
    """Qu·∫£n l√Ω c√°c phi√™n tr√≤ chuy·ªán"""

    def __init__(self):
        self.chat_sessions: Dict[str, ChatHistory] = {}  # L∆∞u tr·ªØ chat history cho m·ªói session
        self.messages: List[Dict[str, Any]] = []

    def add_message(self, role: str, content: str):
        """Th√™m tin nh·∫Øn v√†o l·ªãch s·ª≠"""
        self.messages.append({"role": role, "content": content})

    def get_history(self) -> List[Dict[str, Any]]:
        """L·∫•y to√†n b·ªô l·ªãch s·ª≠ chat"""
        return self.messages

    def get_last_n_messages(self, n: int) -> List[Dict[str, Any]]:
        """L·∫•y n tin nh·∫Øn g·∫ßn nh·∫•t"""
        return self.messages[-n:] if n < len(self.messages) else self.messages

    def get_chat_history(self, session_id: str) -> ChatHistory:
        """L·∫•y ho·∫∑c t·∫°o m·ªõi l·ªãch s·ª≠ chat cho session"""
        if session_id not in self.chat_sessions:
            self.chat_sessions[session_id] = ChatHistory()
            # Th√™m tin nh·∫Øn ch√†o m·ª´ng
            self.chat_sessions[session_id].add_message(
                "Assistant",
                "üíª Ch√†o m·ª´ng b·∫°n ƒë·∫øn v·ªõi AI Gia s∆∞! üöÄ"
            )
        return self.chat_sessions[session_id]

    def progress_message(self, session_id: str, query: str) -> str:
        """X·ª≠ l√Ω tin nh·∫Øn v√† ph·∫£n h·ªìi t·ª´ AI"""
        # L·∫•y chat history
        chat_history = self.get_chat_history(session_id)
        chat_history.add_message("user", query)

        # T·∫°o prompt
        history = chat_history.get_history()
        latest_history = REFLECTION(history, last_items_considered=12)
        prompt = AITutorPrompt(history=latest_history).format()

        # G·ªçi LLM API
        stream = generate_response(prompt)

        # X·ª≠ l√Ω ph·∫£n h·ªìi
        response_text = process_stream(stream)

        # C·∫≠p nh·∫≠t l·ªãch s·ª≠
        chat_history.add_message("Assistant", response_text)

        return response_text
