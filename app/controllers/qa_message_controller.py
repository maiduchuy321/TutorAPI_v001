from app.models.chat_model import ChatHistory
from app.schemas.responses import MessageRequest, MessageResponse, ChatHistoryResponse
from app.controllers.llm_service import generate_response, process_stream
from app.utils.reflection import Reflection
from app.config import REFLECTION
from app.prompt.tutor_prompt import AITutorPrompt
from typing import Dict, List, Any
# L∆∞u tr·ªØ chat history cho m·ªói session
chat_sessions: Dict[str, ChatHistory] = {}

def get_chat_history(session_id: str) -> ChatHistory:
    """L·∫•y ho·∫∑c t·∫°o m·ªõi chat history cho session"""
    if session_id not in chat_sessions:
        chat_sessions[session_id] = ChatHistory()
        # Th√™m tin nh·∫Øn ch√†o m·ª´ng
        chat_sessions[session_id].add_message(
            "Assistant",
            "üíª H·ªçc l·∫≠p tr√¨nh kh√¥ng kh√≥! üöÄ M√¨nh l√† gia s∆∞ AI, gi√∫p b·∫°n ti·∫øp c·∫≠n ki·∫øn th·ª©c l·∫≠p tr√¨nh m·ªôt c√°ch d·ªÖ hi·ªÉu v√† lu√¥n s·∫µn s√†ng ƒë·ªìng h√†nh c√πng b·∫°n tr√™n h√†nh tr√¨nh kh√°m ph√° c√¥ng ngh·ªá. ü§ñ"
        )
    return chat_sessions[session_id]

def progress_message(session_id: str, query):
    # L·∫•y chat history
    chat_history = get_chat_history(session_id)
    chat_history.add_message("user", query)

    # T·∫°o prompt
    history = chat_history.get_history()
    latest_history = REFLECTION(history, last_items_considered=12)
    prompt = AITutorPrompt(history=latest_history).format()

    # G·ªçi LLM API
    stream = generate_response(prompt)

    # X·ª≠ l√Ω ph·∫£n h·ªìi
    response_text = ""
    response_text += process_stream(stream)

    # C·∫≠p nh·∫≠t l·ªãch s·ª≠
    chat_history.add_message("Assistant", response_text)
