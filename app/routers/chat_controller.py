from fastapi import APIRouter, Depends, WebSocket, WebSocketDisconnect
from starlette.websockets import WebSocketState
from datetime import datetime
from typing import Dict, List, Any

from app.models.chat_model import ChatHistory
from app.schemas.responses import MessageRequest, MessageResponse, ChatHistoryResponse
from app.controllers.llm_service import generate_response, process_stream
from app.utils.reflection import Reflection
# from app.prompt import AITutorPrompt
from app.config import REFLECTION
from app.prompt.tutor_prompt import AITutorPrompt
router = APIRouter(
    prefix="/qa",
    tags=["chat"],
    responses={401: {"description": "Unauthorized"}},
)

# L∆∞u tr·ªØ chat history cho m·ªói session
chat_sessions: Dict[str, ChatHistory] = {}


def get_chat_history(session_id: str) -> ChatHistory:
    """L·∫•y ho·∫∑c t·∫°o m·ªõi chat history cho session"""
    if session_id not in chat_sessions:
        chat_sessions[session_id] = ChatHistory()
        # Th√™m tin nh·∫Øn ch√†o m·ª´ng
        chat_sessions[session_id].add_message(
            "Assistant",
            "üíª H·ªçc l·∫≠p tr√¨nh kh√¥ng kh√≥! üöÄ M√¨nh l√† gia s∆∞ AI, gi√∫p b·∫°n ti·∫øp c·∫≠n ki·∫øn th·ª©c l·∫≠p tr√¨nh m·ªôt c√°ch d·ªÖ hi·ªÉu v√† lu√¥n s·∫µn s√†ng ƒë·ªìng h√†nh c√πng b·∫°n tr√™n h√†nh tr√¨nh kh√°m ph√° c√¥ng ngh·ªá. ü§ñ"
        )
    return chat_sessions[session_id]


@router.post("/{session_id}", response_model=MessageResponse)
async def handle_message(session_id: str, message: MessageRequest):
    """
    X·ª≠ l√Ω tin nh·∫Øn ng∆∞·ªùi d√πng v√† tr·∫£ v·ªÅ ph·∫£n h·ªìi t·ª´ LLM.

    Args:
        - **content**: N·ªôi dung tin nh·∫Øn

    Returns:
        MessageResponse: Tin nh·∫Øn ƒë√£ ƒë∆∞·ª£c t·∫°o
    """
    start_time = datetime.now()
    query = message.content

    # L·∫•y chat history
    chat_history = get_chat_history(session_id)
    chat_history.add_message("user", query)

    # T·∫°o prompt
    history = chat_history.get_history()
    latest_history = REFLECTION(history, last_items_considered=8)
    prompt = AITutorPrompt(history=latest_history).format()

    # G·ªçi LLM API
    stream = generate_response(prompt)

    # X·ª≠ l√Ω ph·∫£n h·ªìi
    response_text = ""
    response_text += process_stream(stream)


    # C·∫≠p nh·∫≠t l·ªãch s·ª≠
    chat_history.add_message("Assistant", response_text)

    # T√≠nh th·ªùi gian x·ª≠ l√Ω
    end_time = datetime.now()
    processing_time = (end_time - start_time).total_seconds()

    return MessageResponse(
        content=response_text,
        processing_time=processing_time,
        timestamp=end_time
    )

@router.get("/{session_id}/history", response_model=ChatHistoryResponse)
async def get_history(session_id: str):
    """
    L·∫•y chi ti·∫øt m·ªôt cu·ªôc h·ªôi tho·∫°i theo session_id.

    Args:
        - **session_id (int)**: ID cu·ªôc h·ªôi tho·∫°i

    Returns:
        ConversationResponse: Chi ti·∫øt cu·ªôc h·ªôi tho·∫°i
    """
    chat_history = get_chat_history(session_id)
    return ChatHistoryResponse(messages=chat_history.get_history())